
\chapter{Grundlagen}
\label{sec:Grundlagen}

\section{Scale Invariant Feature Transform}
\label{sift}

\section{Test-Metriken}
\label{sec:TestMetriken}
Das Bilderkennungssystem soll die Bilder in zwei Klassen einordnet: Duplikate und nicht-Duplikate/neue Bilder. 
Da es in diesem Fall bei der Klassifizierung nur zwei mögliche Klassen gibt, kann man das Bilderkennungssystem als binären Klassifikator bezeichnen. 

Die Performance von binären Klassifikatoren kann durch die Werte einer Wahrheitsmatrix quantifiziert werden. 
Die Wahrheitsmatrix gibt dabei an, wie viele richtige und falsche Entscheidungen das System bei der Klassifikation getroffen hat. \cite[S. 170]{classification}

\begin{tabular}[h]{l | l | l}
&\multicolumn{2}{c}{Wahre Klassifikation} \\
System Klassifikation: &Duplikat&nicht-Duplikat \\
\hline
Duplikat&Anzahl wahre Duplikate (TP) &Anzahl falsche Duplikate (FP) \\
\hline
nicht-Duplikat&Anzahl falsche nicht-Duplikate (FN) &Anzahl wahre nicht-Duplikate (TN)
\end{tabular}

Aus den Werten der Wahrheitsmatrix lassen sich weitere Metriken ableiten, die für die Bewertung eines binären Klassifikators nützlich sein können. Interessant für diese Arbeit sind Recall, Spezifizität und Balancierte-Genauigkeit.

Der Recall, oder auch true positive rate, gibt das Verhältnis zwischen den Duplikaten, die das System korrekt klassifiziert hat, und allen Duplikaten, die sich in dem Suchdatensatz befinden, an. \cite[S. 172]{classification}

$$Recall = \frac{ TP }{ TP + FN }$$

Die Spezifizität, oder auch true negative rate, gibt das Verhältnis zwischen den nicht-Duplikaten, die das System korrekt klassifiziert hat, und allen nicht-Duplikaten, die sich im Suchdatensatz befinden an. \cite[S. 172]{classification}

Die Accuracy (dt. Genauigkeit), gibt das Verhältnis zwischen den Bildern, die das System korrekt klassifiziert hat, und allen Bildern im Suchdatensatz an.
Die Genauigkeit spiegelt die Fähigkeit des Systems Bilder richtig zu Klassifizieren wieder.\cite[S. 171]{classification}

Allerdings ist die Genauigkeit kein zuverlässiger Wert, wenn man mit unausgeglichenen Datensätzen arbeitet. 
Ein Datensatz gilt dann als unausgeglichen, wenn einer Klassifikation mehr Elemente angehören, als der anderen Klassifikation. \cite[S. 171]{classification}
In den Testdatensätzen, die für diese Arbeit verwendet werden, befinden sich mehr nicht-Duplikate als Duplikate.
Dieses Ungleichgewicht kann die Genauigkeit stark beeinflussen. So kann zum Beispiel eine gute Spezifizität einen schlechten Recall ausgleichen, wenn der Datensatz zum größten Teil aus nicht-Duplikaten besteht.

Daher kommt bei unbalancierten Datensätzen die balanced-accuracy (dt. Balancierte-Genauigkeit) zum Einsatz. \cite[S. 175]{classification} 
Da sie den Durchschnitt aus Recall und Spezifizität bildet, werden Unterschiede zwischen den beiden Werten ausgeglichen. Dadurch ist die Balancierte-Genauigkeit robust gegenüber unausgeglichenen Datensätzen.